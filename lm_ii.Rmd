---
title: "Multiple Linear Regression Analysis"
description: |
  Linear Regression
author:
  - name: Tehilla Ostrovsky
    url: https://github.com 
    affiliation: LMU
    #affiliation_url: 
date: "`r Sys.Date()`"
output: distill::distill_article
---


## Linear models can be extended to include more than one independent variable, and the equation becomes:


$\color{red}{Y{i}} = \color{blue}{{\alpha}} + \color{green}{{\beta_{1} \times X_{1} + \beta_{2} \times X_{2} + ‚Ä¶ + \beta_{n} \times X_{n}} + \color{orange}{{\epsilon_{i}}}}$


Where $\color{red}{Y_{i}}$ is the dependent variable (what we aim to predict). 

$\color{blue}\alpha$ is the intercept (the point at which the regression line crosses the y axis).


$\color{green}{{X_{1}, X_{2}, X_{n}}}$ are the independent variables (what we measure). 



$\color{green}{{\beta_{1}, \beta_{2}, ..., \beta_{n}}}$ are the slopes of the respective independent variables (tells us how important the respective variable is).


Since we also are interested in the distribution of the residuals, we also estimate $\color{orange}{{\sigma^2}}$, which represents the standard deviation of the error term $\color{orange}\epsilon$.


### In MLR (Multiple Linear Regression) analysis we ask the following questions:

  ## 1) How much variance, relative to the total variability of the criterion, can all predictors explain together?
  ## 2) Which predictor has the largest predictive contribution?
  ## 3) What is the magnitude of the independent predictive contribution of a predictor?
  ## 4) Does the strength, direction, and interpretation of the effect of a predictor change when considering another predictor compared to the multiple regression?
  
  
## We are going to use a fun(ny) example for this topic.  

In a parallel universe, in which Psychology students party during the semester and prior to their exams, a study was conducted...


<img src = "img/student_alcohol.jpg" style = "height:200px; width:300px;border:10px outset silver; display: block; margin-left: auto; margin-right: auto; width: 50%;"></img>



The researchers wanted to know if the amount of alcohol üç∫ consumed consumed a day prior to an exam but also the number of hours spent on preparation üìöüìñ affected the student's exam results &#129351;.  
  

And so they asked students to confess about the amount of ml of alcohol (0 to &#8734;üòÇ) they had the day before the exam and the number hours (0-100) they spent studying and how much they scored in the exam (0-üíØ%). 

## Model Equation: 

### Therefore, the model equation they were about to test is:

$\color{red}{Test.Score_{i}} = \color{blue}{{\alpha}} + \color{green}{{\beta_{alcohol_ml} \times X_{1} + \beta_{Study.hours} \times X_{2}} + \color{orange}{{\epsilon_{i}}}}$



### Here is the data they obtained:

```{r echo=FALSE, warning=FALSE, message=FALSE}
set.seed(123)


# Load the required package
library(mvtnorm)

# Set the desired correlation coefficient
correlation <- 0.6

# Set the means and standard deviations for the variables
mean1 <- 100
sd1 <- 5
mean2 <- 65
sd2 <- 3
mean3 <- 65
sd2 <- 3

# Set the desired sample size
sample_size <- 100
# Generate the correlation matrix
cor_matrix <- matrix(c(1, correlation, correlation, 
                       correlation, 1, correlation, 
                       correlation, correlation, 1), nrow = 3)
# Generate the data based on the correlation matrix
data <- rmvnorm(sample_size, mean = c(mean1, mean2, mean3), sigma = cor_matrix)
data <- round(data, digits = 1)

dat <- as.data.frame(data)



colnames(dat) <-  c("Test_Score", "Drink_ml", "Hours_Studied")

dat$Test_Score <-  ifelse(dat$Test_Score>100, 100, dat$Test_Score)


dat

```


### In this parallel universe the rules are often different to ours but plotting your data is just like in our universe, simply a must! 

## And so they did!


```{r echo=FALSE}
library(shiny)
library(shinyjs)

knitr::include_app("https://tehilla-mechera-ostrovsky.shinyapps.io/de971490be754e3ba279fa31eb04b68e/", 
  height = "600px")
```


# They did not forget to test the MLR assumptions before making public statements about their results...

## 1) They started off with the LINEARITY assumption. To examine this assumption they plotted the residuals of each UV (alcohol in ml and the number of hours spent on studying)
    1.1) First they ran the linear model to be able to tell something about the distribution of the residuals. 
  
  
```{r}
mod <-  lm(Test_Score ~ Drink_ml + Hours_Studied, data = dat)
summary(mod)
```


```{r}
library(car)
crPlots(mod, ylab = "residuals")
```
The blue line represents a linear trend. 

The pink line represents a flexible function that describes the data as closely as possible. 

When both lines are close to each other, the linearity assumption can be considered fulfilled (in our example, none of the variables win this competition).

## Again, 

The <span style="color: blue">blue dashed line</span> shows the  <span style="color: blue">expected residuals if the relationship between the predictor and response variable was linear</span>. 

The <span style="color: #FF33AA">pink line</span> shows the <span style="color: #FF33AA">actual residuals.</span>


**If the two lines are significantly different, then this is evidence of a nonlinear relationship.**


## 2) The next assumption they tested was the NORMALITY. They plotted a histogram of the residuals. Before plotting these, they remembered (of course) to standardize them.
  
```{r}
library(ggplot2)
stand_residuals <-  data.frame(
                    "stand_resid" = c(rstandard(mod)))

# Create a histogram with density line using ggplot2
ggplot(stand_residuals, aes(x = stand_resid)) +
  geom_histogram(fill = "lightblue", color = "black", bins = 15) +
  ylim(0, 10) +
  labs(x = "residuals (standardized)", y = "Frequency", 
       title = "Histogram to Examine Homoskedasticity") +
  theme_classic()

```
  This plot did not make them super happy either.... 
 
 
## 3) lastly, they examined the presence of outliers:
```{r}
cooks_dist <-cooks.distance(model = mod)

plot(cooks_dist, col="lightblue", pch=19, cex=2)
#add labels to every point
text(x = cooks_dist[1:100], labels=c(1:100))
abline(h=4/sample_size)

```
  
##






<!-- ```{r echo=FALSE} -->
<!-- knitr::include_app("https://tehilla-mechera-ostrovsky.shinyapps.io/Bivariat_3d/",  -->
<!--   height = "600px") -->
<!-- ``` -->